{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libreria wordnet in nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i synset associati a un termine, e rispettivi iponimi e iperonimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = 'board'\n",
    "print('\\nExploring senses for term \"{}\"\\n'.format(term))\n",
    "\n",
    "for ss in wn.synsets(term):\n",
    "    print('\\n' + str(ss))\n",
    "    print(ss.name(), ss.lemma_names()) \n",
    "    print('def : ' + ss.definition())\n",
    "    print('ex  : ' + str(ss.examples()))\n",
    "\n",
    "    print('\\n\\t ** Hyponyms **')\n",
    "    for hyp in ss.hyponyms():\n",
    "        print('\\thypon: ' + str(hyp))\n",
    "\n",
    "    print('\\n\\t ** Hypernyms **')\n",
    "    for hyp in ss.hypernyms():\n",
    "        print('\\thyper: ' + str(hyp))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iperonimi di un dato synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('pasta.n.01').hyponyms()\n",
    "\n",
    "for hyp in get_hyponyms(wn.synset('pasta.n.01')):\n",
    "    print(hyp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parti e componenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(wn.synset('car.n.01'), wn.synset('car.n.01').definition())\n",
    "print(wn.synset('car.n.01').part_meronyms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sense similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s1 = wn.synset('dog.n.01')\n",
    "s2 = wn.synset('cat.n.01')\n",
    "print(s1.wup_similarity(s2))\n",
    "\n",
    "\n",
    "# NB: wup_similarity Ã¨ la Wu & Palmer similarity, che dobbiamo reimplementare\n",
    "\n",
    "# for ss1 in wn.synsets('dog'):\n",
    "#     for ss2 in wn.synsets('cat'):\n",
    "#         print('sim ' + str(ss1) + ', ' + str(ss2) + ' = ' + str(ss1.wup_similarity(ss2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verbi e entailment (implicazione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Exploring entailment relation in verbs')\n",
    "verb = 'snore' # RUSSARE...\n",
    "count = 1\n",
    "# NB: con il secondo parametro selezioniamo il PoS, in questo caso VB\n",
    "for ss in wn.synsets(verb, 'v'):\n",
    "    print('sense {}({}): to {} implies to {}'.format(count, ss, verb, ss.entailments()))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit8adf240491474df8aebe7a540fc75b38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
